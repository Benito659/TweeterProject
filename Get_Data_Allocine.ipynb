{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03fc5e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Scraping movies informations available on Allocine.fr\"\"\"\n",
    "\n",
    "import datetime\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "import unicodedata\n",
    "from random import randrange\n",
    "from typing import Dict, List, Optional, Union\n",
    "\n",
    "import bs4\n",
    "import dateparser\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from loguru import logger\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "logger.remove()\n",
    "logger.add(\"scraper.log\", rotation=\"100 MB\")\n",
    "logger.add(sys.stderr, level=\"CRITICAL\")\n",
    "\n",
    "\n",
    "class AllocineScraper:\n",
    "    \"\"\"Main class for scraping Allociné.fr\n",
    "    Attributes\n",
    "    ----------\n",
    "    ALLOCINE_URL (str):\n",
    "        Base URL where we will get movie attributes.\n",
    "    df (pd.DataFrame):\n",
    "        Pandas DataFrame with all the scraped informations.\n",
    "    output_dir (str):\n",
    "        Output directory for the csv file\n",
    "    output_csv_name (str):\n",
    "        CSV Filename of the Pandas DataFrame that hosts all our movie results.\n",
    "    pause_scraping (list):\n",
    "        Random time to wait before each page scraped.\n",
    "    movie_infos (list):\n",
    "        List of movie attributes we're interested in.\n",
    "    number_of_pages (int):\n",
    "        How many pages to scrap on Allociné.fr.\n",
    "    from_page (int):\n",
    "        first page number to scrape.\n",
    "    \"\"\"\n",
    "\n",
    "    ALLOCINE_URL = \"https://www.allocine.fr/films/?page=\"\n",
    "\n",
    "    movie_infos = [\n",
    "        \"id\",\n",
    "        \"title\",\n",
    "        \"release_date\",\n",
    "        \"duration\",\n",
    "        \"genres\",\n",
    "        \"directors\",\n",
    "        \"actors\",\n",
    "        \"nationality\",\n",
    "        \"press_rating\",\n",
    "        \"number_of_press_rating\",\n",
    "        \"spec_rating\",\n",
    "        \"number_of_spec_rating\",\n",
    "        \"summary\",\n",
    "    ]\n",
    "\n",
    "    df = pd.DataFrame(columns=movie_infos)\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        number_of_pages: Optional[int] = 10,\n",
    "        from_page: Optional[int] = 1,\n",
    "        output_dir: Optional[str] = \"data\",\n",
    "        output_csv_name: Optional[str] = \"allocine_movies.csv\",\n",
    "        pause_scraping: Optional[List[int]] = None,\n",
    "        append_result=False,\n",
    "    ) -> None:\n",
    "        \"\"\"Initializes our Scraper class.\n",
    "        Parameters\n",
    "        ----------\n",
    "        number_of_pages : Optional[int], Optional, Default = 10\n",
    "            number of pages to scrape\n",
    "        from_page : Optional[int], Optional, Default = 1\n",
    "            first page number to scrape. default: 1\n",
    "        output_csv_name : Optional[str], Optional, Default = allocine_movies.csv\n",
    "            output csv name.\n",
    "        pause_scraping : Optional[List[int]], default = [2, 10]\n",
    "            Number of secondes to wait before scraping the next page.\n",
    "            Use a fixe number of second or a list of two integer\n",
    "            to get a random number of seconds.\n",
    "        Raises\n",
    "        ------\n",
    "        Exception:\n",
    "            Exits the scraper if the arguments are not appropriate.\n",
    "        \"\"\"\n",
    "\n",
    "        if not isinstance(number_of_pages, int) or number_of_pages < 1:\n",
    "            raise ValueError(f\"<{number_of_pages=}> must be an integer superior to 1.\")\n",
    "\n",
    "        self.number_of_pages = number_of_pages\n",
    "\n",
    "        if not isinstance(from_page, int) or from_page < 1:\n",
    "            raise ValueError(f\"<{from_page=}> must be an integer superior to 0.\")\n",
    "\n",
    "        self.from_page = from_page\n",
    "\n",
    "        if not isinstance(output_dir, str):\n",
    "            raise ValueError(f\"<{output_dir=}> must have a valid name.\")\n",
    "\n",
    "        self.output_dir = output_dir\n",
    "\n",
    "        if not isinstance(output_csv_name, str) or output_csv_name[-4:] != \".csv\":\n",
    "            raise ValueError(f\"<{output_csv_name=}> must have a valid CSV name.\")\n",
    "\n",
    "        self.output_csv_name = output_csv_name\n",
    "\n",
    "        if not pause_scraping:\n",
    "            pause_scraping = [2, 10]\n",
    "\n",
    "        if not isinstance(pause_scraping, list):\n",
    "            raise ValueError(\n",
    "                f\"<{pause_scraping=}> must be an integer or a list of integer\"\n",
    "            )\n",
    "\n",
    "        self.pause_scraping = pause_scraping\n",
    "        self.append_result = append_result\n",
    "        self.full_path_csv = f\"{self.output_dir}/{self.output_csv_name}\"\n",
    "\n",
    "        logger.info(\"Initializing Allocine Scraper...\")\n",
    "        logger.info(f\"- Number of pages to scrap: {self.number_of_pages}\")\n",
    "        logger.info(\n",
    "            f\"\"\"- Time to wait between pages between :\n",
    "            {self.pause_scraping[0]} sec and {self.pause_scraping[1]} sec\"\"\"\n",
    "        )\n",
    "        logger.info(f\"- Results will be stored in: <{self.full_path_csv}>\")\n",
    "\n",
    "        if self.append_result:\n",
    "            try:\n",
    "                self.df = pd.read_csv(self.full_path_csv)\n",
    "                self.exclude_ids = self.df[\"id\"].dropna().astype(int).tolist()\n",
    "                logger.info(\n",
    "                    f\"\"\"- The list to exclude movies already fetch has been initialize\n",
    "                    -- Total movie listed: {len(self.exclude_ids)}\"\"\"\n",
    "                )\n",
    "            except Exception as ex:\n",
    "                logger.error(f\"Failed to load the csv {self.full_path_csv} -- {ex}\")\n",
    "                raise FileNotFoundError(\n",
    "                    f\"Failed to load the csv {self.full_path_csv} -- {ex}\"\n",
    "                )\n",
    "        else:\n",
    "            self.exclude_ids = []\n",
    "\n",
    "    def _get_page(self, page_number: int) -> requests.models.Response:\n",
    "        \"\"\"Private method to get the full content of a webpage.\n",
    "        Parameters\n",
    "        ----------\n",
    "        page_number (int):\n",
    "            Number of the page on Allociné.fr.\n",
    "        Returns\n",
    "        -------\n",
    "        requests.models.Response:\n",
    "            Full source code of the asked webpage.\n",
    "        \"\"\"\n",
    "\n",
    "        response = requests.get(\n",
    "            self.ALLOCINE_URL + str(page_number)\n",
    "        )  # pragma: no cover\n",
    "        return response\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_movie(url: str) -> requests.models.Response:\n",
    "        \"\"\"Private method to get the full content of a movie webpage.\n",
    "        Parameters\n",
    "        ----------\n",
    "        url (str):\n",
    "            movie url to scrape.\n",
    "        Returns\n",
    "        -------\n",
    "        requests.models.Response:\n",
    "            Full source code of the asked webpage.\n",
    "        \"\"\"\n",
    "        response = requests.get(f\"http://www.allocine.fr{url}\")  # pragma: no cover\n",
    "        return response\n",
    "\n",
    "    def _randomize_waiting_time(self) -> int:\n",
    "        \"\"\"Private method to get a random waiting time.\"\"\"\n",
    "        return randrange(*self.pause_scraping)\n",
    "\n",
    "    @staticmethod\n",
    "    def _create_directory_if_not_exist(path_dir: str) -> None:\n",
    "        if not os.path.exists(path_dir):\n",
    "            logger.info(f\"{path_dir} doesn't exist. We try to create it...\")\n",
    "            try:\n",
    "                os.makedirs(path_dir)\n",
    "            except Exception as ex:  # pragma: no cover\n",
    "                logger.error(f\"Failed to create {path_dir}: {ex}\")\n",
    "                raise OSError(f\"Failed to create {path_dir}: {ex}\")\n",
    "\n",
    "    def _parse_page(self, page: requests.models.Response) -> List[str]:\n",
    "        \"\"\"Private method to parse a single result page from Allociné.fr.\n",
    "        Parameters\n",
    "        ----------\n",
    "        page (str):\n",
    "            Source code of a Allocine.fr webpage.\n",
    "        Returns\n",
    "        -------\n",
    "        List:\n",
    "            list of movie page urls\n",
    "        \"\"\"\n",
    "\n",
    "        parser = BeautifulSoup(page.content, \"html.parser\")\n",
    "        urls = [url.a[\"href\"] for url in parser.find_all(\"h2\", class_=\"meta-title\")]\n",
    "\n",
    "        if self.append_result and self.exclude_ids:\n",
    "            ori_urls_len = len(urls)\n",
    "            urls = [\n",
    "                url\n",
    "                for url in urls\n",
    "                if int(url.split(\"=\")[-1].split(\".\")[0]) not in self.exclude_ids\n",
    "            ]\n",
    "            urls_len = len(urls)\n",
    "            logger.info(\n",
    "                f\"\"\"{ori_urls_len - urls_len} / {ori_urls_len}\n",
    "                movies has already been scraped\"\"\"\n",
    "            )\n",
    "\n",
    "        return urls\n",
    "\n",
    "    def _parse_movie(self, page: requests.models.Response) -> None:\n",
    "        parser = BeautifulSoup(page.content, \"html.parser\")\n",
    "        parser_movie = parser.find(\"main\", {\"id\": \"content-layout\"})\n",
    "\n",
    "        self._create_directory_if_not_exist(self.output_dir)\n",
    "\n",
    "        movie_datas: Dict = {}\n",
    "\n",
    "        for info in self.movie_infos:\n",
    "            try:\n",
    "                scraped_info = getattr(self, \"_get_movie_\" + info)(parser_movie)\n",
    "            except AttributeError as ex:  # pragma: no cover\n",
    "                logger.error(f\"<id:{movie_datas.get('id')}, info:{info}>: {ex}\")\n",
    "                scraped_info = None\n",
    "\n",
    "            movie_datas[info] = [scraped_info]\n",
    "\n",
    "        self.df = pd.concat([self.df, pd.DataFrame(movie_datas)], ignore_index=True)\n",
    "\n",
    "        self.df.drop_duplicates(subset=[\"id\"]).to_csv(\n",
    "            f\"{self.full_path_csv}\", index=False\n",
    "        )\n",
    "\n",
    "    def scraping_movies(self) -> None:\n",
    "        \"\"\"Starts the scraping process.\"\"\"\n",
    "\n",
    "        logger.info(\"Starting scraping movies from Allocine...\")\n",
    "\n",
    "        for number in tqdm(\n",
    "            range(self.from_page, self.from_page + self.number_of_pages), desc=\"Pages\"\n",
    "        ):\n",
    "\n",
    "            logger.info(\n",
    "                f\"Fetching Page {number}/{self.from_page + self.number_of_pages}\"\n",
    "            )\n",
    "            time.sleep(self._randomize_waiting_time())\n",
    "            res_page = self._get_page(number)\n",
    "            urls_to_parse = self._parse_page(res_page)\n",
    "\n",
    "            for url in tqdm(\n",
    "                urls_to_parse,\n",
    "                desc=\"Movies\",\n",
    "                leave=(number == (self.from_page + self.number_of_pages - 1)),\n",
    "            ):\n",
    "                logger.info(f\"Fetching Movie {url}\")\n",
    "                res_movie = self._get_movie(url)\n",
    "                self._parse_movie(res_movie)\n",
    "\n",
    "                self.exclude_ids.append(int(url.split(\"=\")[-1].split(\".\")[0]))\n",
    "                sleep_timer = self._randomize_waiting_time()\n",
    "                logger.info(\n",
    "                    f\"\"\"Done Fetching {url}.\n",
    "                    Waiting {sleep_timer} sec before the next one...\"\"\"\n",
    "                )\n",
    "                time.sleep(sleep_timer)\n",
    "\n",
    "            sleep_timer = self._randomize_waiting_time()\n",
    "            logger.info(\n",
    "                f\"\"\"Done scraping page #{number}.\n",
    "                Waiting {sleep_timer} sec before the next one...\"\"\"\n",
    "            )\n",
    "            time.sleep(sleep_timer)\n",
    "\n",
    "        logger.info(\"Done scraping Allocine.\")\n",
    "        logger.info(f\"Results are stored in {self.output_csv_name}.\")\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_movie_id(movie: bs4.element.Tag) -> int:\n",
    "        \"\"\"Private method to retrieve the movie ID according to Allociné.\n",
    "        Args:\n",
    "            movie (bs4.element.Tag): Parser results with the movie page informations.\n",
    "        Returns:\n",
    "            int: The movie ID according to Allociné.\n",
    "        \"\"\"\n",
    "\n",
    "        movie_id = re.sub(\n",
    "            r\"\\D\", \"\", movie.find(\"nav\", {\"class\": \"third-nav\"}).a[\"href\"]\n",
    "        )\n",
    "\n",
    "        return int(movie_id)\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_movie_title(movie: bs4.element.Tag) -> str:\n",
    "        \"\"\"Private method to retrieve the movie title.\n",
    "        Args:\n",
    "            movie (bs4.element.Tag): Parser results with the movie page informations.\n",
    "        Returns:\n",
    "            str: The movie title.\n",
    "        \"\"\"\n",
    "\n",
    "        movie_title = movie.find(\"div\", {\"class\": \"titlebar-title\"}).text.strip()\n",
    "\n",
    "        return movie_title\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_movie_release_date(\n",
    "        movie: bs4.element.Tag,\n",
    "    ) -> Union[datetime.datetime, None]:\n",
    "        \"\"\"Private method to retrieve the movie release date.\n",
    "        Args:\n",
    "            movie (bs4.element.Tag): Parser results with the movie page informations.\n",
    "        Returns:\n",
    "            datetime.datetime: The movie release date.\n",
    "        \"\"\"\n",
    "\n",
    "        movie_date = movie.find(\"span\", {\"class\": \"date\"})\n",
    "        if movie_date:\n",
    "            movie_date = movie_date.text.strip()\n",
    "            movie_date = dateparser.parse(movie_date, date_formats=[\"%d %B %Y\"])\n",
    "        return movie_date\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_movie_duration(movie: bs4.element.Tag) -> int:\n",
    "        \"\"\"Private method to retrieve the movie duration.\n",
    "        Args:\n",
    "            movie (bs4.element.Tag): Parser results with the movie page informations.\n",
    "        Returns:\n",
    "            int: The movie duration in minutes.\n",
    "        \"\"\"\n",
    "\n",
    "        movie_duration = movie.find(\"span\", {\"class\": \"spacer\"}).next_sibling.strip()\n",
    "        if movie_duration != \"\":\n",
    "            duration_timedelta = pd.to_timedelta(movie_duration).components\n",
    "            movie_duration = duration_timedelta.hours * 60 + duration_timedelta.minutes\n",
    "\n",
    "        return movie_duration\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_movie_genres(movie: bs4.element.Tag) -> Union[str, None]:\n",
    "        \"\"\"Private method to retrieve the movie genre(s).\n",
    "        Args:\n",
    "            movie (bs4.element.Tag): Parser results with the movie page informations.\n",
    "        Returns:\n",
    "            Union[str, None]: The movie genre(s).\n",
    "        \"\"\"\n",
    "        div_genres = movie.find(\"div\", {\"class\": \"meta-body-item meta-body-info\"})\n",
    "\n",
    "        if div_genres:\n",
    "            movie_genres = [\n",
    "                genre.text\n",
    "                for genre in div_genres.find_all(\"span\", class_=re.compile(r\".*==$\"))\n",
    "                if \"\\n\" not in genre.text\n",
    "            ]\n",
    "\n",
    "            return \", \".join(movie_genres)\n",
    "\n",
    "        return None\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_movie_directors(movie: bs4.element.Tag) -> Union[str, None]:\n",
    "        \"\"\"Private method to retrieve the movie director(s).\n",
    "        Args:\n",
    "            movie (bs4.element.Tag): Parser results with the movie page informations.\n",
    "        Returns:\n",
    "            Union[str, None]: The movie director(s).\n",
    "        \"\"\"\n",
    "        div_directors = movie.find(\n",
    "            \"div\", {\"class\": \"meta-body-item meta-body-direction\"}\n",
    "        )\n",
    "        if div_directors:\n",
    "            movie_directors = [\n",
    "                link.text\n",
    "                for link in div_directors.find_all(\n",
    "                    [\"a\", \"span\"], class_=re.compile(r\".*blue-link$\")\n",
    "                )\n",
    "            ]\n",
    "\n",
    "            return \", \".join(movie_directors)\n",
    "\n",
    "        return None\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_movie_actors(movie: bs4.element.Tag) -> Union[str, None]:\n",
    "        \"\"\"Private method to retrieve the movie actor(s).\n",
    "        Args:\n",
    "            movie (bs4.element.Tag): Parser results with the movie page informations.\n",
    "        Returns:\n",
    "            Union[str, None]: The movie actor(s).\n",
    "        \"\"\"\n",
    "        div_actors = movie.find(\"div\", {\"class\": \"meta-body-item meta-body-actor\"})\n",
    "\n",
    "        if div_actors:\n",
    "            movie_actors = [actor.text for actor in div_actors.find_all([\"a\", \"span\"])][\n",
    "                1:\n",
    "            ]\n",
    "\n",
    "            return \", \".join(movie_actors)\n",
    "\n",
    "        return None\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_movie_nationality(movie: bs4.element.Tag) -> str:\n",
    "        \"\"\"Private method to retrieve the movie nationality.\n",
    "        Args:\n",
    "            movie (bs4.element.Tag): Parser results with the movie page informations.\n",
    "        Returns:\n",
    "            str: The movie nationality.\n",
    "        \"\"\"\n",
    "\n",
    "        movie_nationality = [\n",
    "            nationality.text.strip()\n",
    "            for nationality in movie.find_all(\"span\", class_=\"nationality\")\n",
    "        ]\n",
    "\n",
    "        return \", \".join(movie_nationality)\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_movie_press_rating(movie: bs4.element.Tag) -> Union[float, None]:\n",
    "        \"\"\"Private method to retrieve the movie rating according to the press.\n",
    "        Args:\n",
    "            movie (bs4.element.Tag): Parser results with the movie page informations.\n",
    "        Returns:\n",
    "            Union[float, None]: The movie rating according to the press.\n",
    "        \"\"\"\n",
    "\n",
    "        # get all the available ratings\n",
    "        movie_ratings = movie.find_all(\"div\", class_=\"rating-item\")\n",
    "\n",
    "        for ratings in movie_ratings:\n",
    "\n",
    "            if \"Presse\" in ratings.text:\n",
    "                return float(\n",
    "                    re.sub(\n",
    "                        \",\", \".\", ratings.find(\"span\", {\"class\": \"stareval-note\"}).text\n",
    "                    )\n",
    "                )\n",
    "        return None\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_movie_number_of_press_rating(movie: bs4.element.Tag) -> Union[float, None]:\n",
    "        \"\"\"Private method to retrieve number of ratings from the press.\n",
    "        Args:\n",
    "            movie (bs4.element.Tag): Parser results with the movie page informations.\n",
    "        Returns:\n",
    "            Union[float, None]: The movie rating according to the press.\n",
    "        \"\"\"\n",
    "\n",
    "        # get all the available ratings\n",
    "        movie_ratings = movie.find_all(\"div\", class_=\"rating-item\")\n",
    "\n",
    "        for ratings in movie_ratings:\n",
    "\n",
    "            if \"Presse\" in ratings.text:\n",
    "                return float(\n",
    "                    re.sub(\n",
    "                        r\"\\D\",\n",
    "                        \"\",\n",
    "                        ratings.find(\"span\", {\"class\": \"stareval-review\"}).text,\n",
    "                    )\n",
    "                )\n",
    "        return None\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_movie_spec_rating(movie: bs4.element.Tag) -> Union[float, None]:\n",
    "        \"\"\"Private method to retrieve the movie rating according to the spectators.\n",
    "        Args:\n",
    "            movie (bs4.element.Tag): Parser results with the movie page informations.\n",
    "        Returns:\n",
    "            Union[float, None]: The number of ratings from to the spectators.\n",
    "        \"\"\"\n",
    "\n",
    "        # get all the available ratings\n",
    "        movie_ratings = movie.find_all(\"div\", class_=\"rating-item\")\n",
    "\n",
    "        for ratings in movie_ratings:\n",
    "\n",
    "            if \"Spectateurs\" in ratings.text:\n",
    "                return float(\n",
    "                    re.sub(\n",
    "                        \",\", \".\", ratings.find(\"span\", {\"class\": \"stareval-note\"}).text\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        return None\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_movie_number_of_spec_rating(movie: bs4.element.Tag) -> Union[float, None]:\n",
    "        \"\"\"Private method to retrieve number of ratings from the spectators.\n",
    "        Args:\n",
    "            movie (bs4.element.Tag): Parser results with the movie page informations.\n",
    "        Returns:\n",
    "            Union[float, None]: The number of ratings from according to the press.\n",
    "        \"\"\"\n",
    "\n",
    "        # get all the available ratings\n",
    "        movie_ratings = movie.find_all(\"div\", class_=\"rating-item\")\n",
    "\n",
    "        for ratings in movie_ratings:\n",
    "\n",
    "            if \"Spectateurs\" in ratings.text:\n",
    "                return float(\n",
    "                    re.sub(\n",
    "                        r\"\\D\",\n",
    "                        \"\",\n",
    "                        ratings.find(\"span\", {\"class\": \"stareval-review\"}).text,\n",
    "                    )\n",
    "                )\n",
    "        return None\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_movie_summary(movie: bs4.element.Tag) -> Union[str, None]:\n",
    "        \"\"\"Private method to retrieve the movie summary.\n",
    "        Args:\n",
    "            movie (bs4.element.Tag): Parser results with the movie page informations.\n",
    "        Returns:\n",
    "            Union[str, None]: The movie summary.\n",
    "        \"\"\"\n",
    "\n",
    "        movie_summary = movie.find(\n",
    "            \"section\", {\"class\": \"section ovw ovw-synopsis\"}\n",
    "        ).find(\"div\", {\"class\": \"content-txt\"})\n",
    "\n",
    "        if movie_summary:\n",
    "            movie_summary = movie_summary.text.strip()\n",
    "            return unicodedata.normalize(\"NFKC\", movie_summary)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55dbcf47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "887b1ee676474b5fb66b881d8ace04ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pages:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Movies:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Movies:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Movies:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Movies:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6235807320954513a7303acc2137ec36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Movies:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-16dccb1beced>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m   )\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mscraper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscraping_movies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-771fc4cd373d>\u001b[0m in \u001b[0;36mscraping_movies\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    271\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Fetching Movie {url}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m                 \u001b[0mres_movie\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_movie\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 273\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parse_movie\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres_movie\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    274\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexclude_ids\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"=\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\".\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-771fc4cd373d>\u001b[0m in \u001b[0;36m_parse_movie\u001b[1;34m(self, page)\u001b[0m\n\u001b[0;32m    235\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmovie_infos\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 237\u001b[1;33m                 \u001b[0mscraped_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_get_movie_\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparser_movie\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    238\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pragma: no cover\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"<id:{movie_datas.get('id')}, info:{info}>: {ex}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-771fc4cd373d>\u001b[0m in \u001b[0;36m_get_movie_id\u001b[1;34m(movie)\u001b[0m\n\u001b[0;32m    301\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m         movie_id = re.sub(\n\u001b[1;32m--> 303\u001b[1;33m             \u001b[1;34mr\"\\D\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmovie\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nav\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"class\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"third-nav\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"href\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    304\u001b[0m         )\n\u001b[0;32m    305\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "scraper = AllocineScraper(\n",
    "  number_of_pages = 20,\n",
    "  from_page = 55,\n",
    "  output_dir = \"data\",\n",
    "  output_csv_name = \"allocine_movies.csv\",\n",
    "  pause_scraping = [0, 10],\n",
    "  append_result=False\n",
    "  )\n",
    "  \n",
    "scraper.scraping_movies()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
